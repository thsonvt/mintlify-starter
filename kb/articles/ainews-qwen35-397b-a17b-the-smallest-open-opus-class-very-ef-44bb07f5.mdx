---
title: '[AINews] Qwen3.5-397B-A17B: the smallest Open-Opus class, very efficient model'
description: 'Qwen 3.5 is a new model from Qwen.AI, featuring improvements in multimodality and spatial intelligence, and is positioned alongside other leading mode'
icon: 'newspaper'
author: 'Swyx'
authorId: 'swyx'
published: '2026-02-17'
sourceUrl: 'https://www.latent.space/p/ainews-qwen35-397b-a17b-the-smallest'
topics: ["ai-models","multimodal-ai","spatial-intelligence"]
diataxisType: 'explanation'
---

<Info>
**Original**: [Swyx](https://www.latent.space/p/ainews-qwen35-397b-a17b-the-smallest) · 17/02/2026
</Info>

## Summary

Qwen 3.5 is a new model from Qwen.AI, featuring improvements in multimodality and spatial intelligence, and is positioned alongside other leading models in its class.

## Key Insights

> "Qwen 3.5 is in the same weight class as Kimi, 400B with about a 4.3% sparsity ratio."
>
> — Comparison of Qwen 3.5 with other models in terms of weight and sparsity.

> "Native Multimodality and Spatial Intelligence are headline features of the model."
>
> — Highlighting the key features of the Qwen 3.5 model.

> "This is a very welcome headline model refresh from China's most prolific open model lab."
>
> — Commenting on the significance of the Qwen 3.5 release.

## Topics

- [ai-models](/kb/topics/ai-models)
- [multimodal-ai](/kb/topics/multimodal-ai)
- [spatial-intelligence](/kb/topics/spatial-intelligence)

---

## Full Article

a good ship from Qwen.AI News for 2/13/2026-2/16/2026. We checked 12 subreddits, 544 Twitters and 24 Discords (261 channels, and 26057 messages) for you. Estimated reading time saved (at 200wpm): 2606 minutes. AINews website lets you search all past issues. As a reminder, AINews is now a section of Latent Space. You can opt in/out of email frequencies!Congrats to Pete Steinberger on joining OpenAI, as we predicted. Not much else to add there so we wont.Todays headliner is Qwen 3.5, which followed the other Chinese model labs like Z.ai and Minimax and Kimi in refreshing their leading models, but unlike the first two, Qwen 3.5 is in the same weight class as Kimi, 400B with about a 4.3% sparsity ratio instead of Kimis more agressive 3.25%. They do not claim SOTA across the board, and most notably not across coding benchmarks, but make solid improvements compared to Qwen3-Max and Qwen3-VL.Native Multimodality and Spatial Intelligence are headline features of the model and we encourage clicking over to the blog to check out the examples, as there isnt much else to say - this is a very welcome headline model refresh from Chinas most prolific open model lab, and probably the last before DeepSeek v4.AI Twitter Recap Read more

---

## Related Articles

<CardGroup cols={1}>
  <Card
    title="[AINews] Qwen Image 2 and Seedance 2"
    icon="newspaper"
    href="/kb/articles/ainews-qwen-image-2-and-seedance-2-91fc2890"
  >
    Swyx · explanation · 74% similar
  </Card>
  <Card
    title="[AINews] Context Graphs and Agent Traces"
    icon="newspaper"
    href="/kb/articles/ainews-context-graphs-and-agent-traces-ee58e399"
  >
    Swyx · explanation · 69% similar
  </Card>
  <Card
    title="[AINews] ElevenLabs $500m Series D at $11B, Cerebras $1B Series H at $23B, Vibe Coding -> Agentic Engineering"
    icon="newspaper"
    href="/kb/articles/ainews-elevenlabs-500m-series-d-at-11b-cerebras-1b-series-h--f99e1824"
  >
    Swyx · reference · 69% similar
  </Card>
</CardGroup>

---

<Note>
Originally published at [https://www.latent.space/p/ainews-qwen35-397b-a17b-the-smallest](https://www.latent.space/p/ainews-qwen35-397b-a17b-the-smallest).
</Note>
