---
title: 'How to do AI analysis you can actually trust'
description: 'Ever run an AI analysis on customer data, only to discover the numbers were fabricated and the insights completely generic? [![](https://substackcdn.c'
icon: 'newspaper'
author: 'Lenny Rachitsky'
authorId: 'lenny-rachitsky'
published: '2026-02-17'
sourceUrl: 'https://www.lennysnewsletter.com/p/how-to-do-ai-analysis-you-can-actually-db6'
topics: ["Agent-Native Architecture","Prompt Engineering","AI Agents"]
diataxisType: 'how-to'
---

<Info>
**Original**: [Lenny Rachitsky](https://www.lennysnewsletter.com/p/how-to-do-ai-analysis-you-can-actually-db6) Â· 17/02/2026
</Info>

## Summary

Ever run an AI analysis on customer data, only to discover the numbers were fabricated and the insights completely generic? [![](https://substackcdn.com/image/fetch/$s_!OYz9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d4c0b48-1813-4432-894d-5011ef111807_3016x3016.png)](https://substackcdn.com/image/fetch/$s_!OYz9!,f_auto,q_auto:good,fl_pr

## Key Insights

> "Ever run an AI analysis on customer data, only to discover the numbers were fabricated and the insights completely generic?"
>
> â€” Introducing the problem of unreliable AI analysis.

> "After 2,000+ hours of testing customer discovery workflows with AI, sheâ€™s identified the failure modes that break AI analysis and the reliable fixes for each one."
>
> â€” Highlighting Caitlin Sullivan's extensive experience and the value of her insights.

> "The final verification pass that stress-tests everything before it hits a deck."
>
> â€” Emphasizing the importance of verification in AI analysis.

## Topics

- [Agent-Native Architecture](/kb/topics/agent-native-architecture)
- [Prompt Engineering](/kb/topics/prompt-engineering)
- [AI Agents](/kb/topics/ai-agents)

---

## Full Article

```
# How to do AI analysis you can actually trust
```

**Author**: Lenny Rachitsky  
**Published**: 2026-02-17  
**Source**: [https://www.lennysnewsletter.com/p/how-to-do-ai-analysis-you-can-actually-db6](https://www.lennysnewsletter.com/p/how-to-do-ai-analysis-you-can-actually-db6)

---

```
[![](https://substackcdn.com/image/fetch/$s_!OYz9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d4c0b48-1813-4432-894d-5011ef111807_3016x3016.png)](https://substackcdn.com/image/fetch/$s_!OYz9!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d4c0b48-1813-4432-894d-5011ef111807_3016x3016.png)
```

***If youâ€™re a premium subscriber***

*Add the private feed to your podcast app at [add.lennysreads.com](https://add.lennysreads.com/)*

Ever run an AI analysis on customer data, only to discover the numbers were fabricated and the insights completely generic? In this episode, Caitlin Sullivan, a user-research veteran whoâ€™s trained hundreds of product and research professionals, shares her four prompting techniques for getting trustworthy, actionable insights out of any LLM. After 2,000+ hours of testing customer discovery workflows with AI, sheâ€™s identified the failure modes that break AI analysis and the reliable fixes for each one.

***Listen now: [YouTube](https://www.youtube.com/@lennysreads) | [Apple](https://podcasts.apple.com/us/podcast/lennys-reads/id1810314693) | [Spotify](https://open.spotify.com/show/0IIunA06qMtrcQLfypTooj)***

**In this episode, youâ€™ll learn:**

```
* How to catch the two types of AI quote hallucinations
* Why AI defaults to useless generic themes and insights
* Which LLM is best for analysis work (and which one fabricates the most)
* How to turn vague signal into actual decision clarity
* The final verification pass that stress-tests everything before it hits a deck
```

**Referenced**

```
* [Caitlin Sullivan](https://www.linkedin.com/in/caitlindsullivan/)

[Read more](https://www.lennysnewsletter.com/p/how-to-do-ai-analysis-you-can-actually-db6)
```

---

## Key Takeaways

### Notable Quotes

> Ever run an AI analysis on customer data, only to discover the numbers were fabricated and the insights completely generic?

*Context: Introducing the problem of unreliable AI analysis.*

> After 2,000+ hours of testing customer discovery workflows with AI, sheâ€™s identified the failure modes that break AI analysis and the reliable fixes for each one.

*Context: Highlighting Caitlin Sullivan's extensive experience and the value of her insights.*

> The final verification pass that stress-tests everything before it hits a deck.

*Context: Emphasizing the importance of verification in AI analysis.*

## Related Topics

- [[topics/agent-native-architecture]]
- [[topics/prompt-engineering]]
- [[topics/ai-agents]]

---

## Related Articles

<CardGroup cols={1}>
  <Card
    title="Building AI product sense, part 2"
    icon="newspaper"
    href="/kb/articles/building-ai-product-sense-part-2-35ea6c02"
  >
    Lenny Rachitsky Â· explanation Â· 79% similar
  </Card>
  <Card
    title="ðŸŽ™ï¸ This week on How I AI: How to build your own AI developer tools with Claude Code"
    icon="newspaper"
    href="/kb/articles/-this-week-on-how-i-ai-how-to-build-your-own-ai-developer-to-db8b7ca4"
  >
    Lenny Rachitsky Â· how-to Â· 78% similar
  </Card>
  <Card
    title="How to do AI analysis you can actually trust"
    icon="newspaper"
    href="/kb/articles/how-to-do-ai-analysis-you-can-actually-trust-5062827b"
  >
    Lenny Rachitsky Â· how-to Â· 77% similar
  </Card>
</CardGroup>

---

<Note>
Originally published at [https://www.lennysnewsletter.com/p/how-to-do-ai-analysis-you-can-actually-db6](https://www.lennysnewsletter.com/p/how-to-do-ai-analysis-you-can-actually-db6).
</Note>
